
@article{lasagne,
  title = {Lasagne: {{First}} Release.},
  url = {http://dx.doi.org/10.5281/zenodo.27878},
  doi = {10.5281/zenodo.27878},
  timestamp = {2017-02-07T15:51:26Z},
  author = {Dieleman, Sander and Schlüter, Jan and Raffel, Colin and Olson, Eben and Sønderby, Søren Kaae and {others}},
  date = {2015-08},
  groups = {other}
}

@article{theano,
  title = {Theano: {{A Python}} Framework for Fast Computation of Mathematical Expressions},
  volume = {abs/1605.02688},
  url = {http://arxiv.org/abs/1605.02688},
  timestamp = {2017-02-07T15:51:27Z},
  journaltitle = {arXiv e-prints},
  author = {{Theano Development Team}},
  date = {2016-05},
  keywords = {Computer Science - Learning,Computer Science - Mathematical Software,Computer Science - Symbolic Computation},
  groups = {other},
  primaryclass = {cs.SC}
}

@article{swda,
  title = {Switchboard Discourse Language Modeling Project},
  timestamp = {2017-02-07T15:51:27Z},
  author = {Jurafsky, Daniel and Van Ess-Dykema, Carol and {others}},
  date = {1997},
  groups = {other}
}

@article{swb,
  title = {Switchboard-1 {{Release}} 2},
  url = {https://catalog.ldc.upenn.edu/ldc97s62},
  timestamp = {2017-02-07T15:51:27Z},
  author = {Godfrey, John and Holliman, Edward},
  date = {1993},
  groups = {other}
}

@article{swbalign,
  title = {{{ISIP Switchboard}} Word Alignments},
  url = {https://www.isip.piconepress.com/projects/switchboard/},
  timestamp = {2017-02-07T15:51:27Z},
  author = {Harkins, Dan and {others}},
  date = {2003},
  groups = {other}
}

@article{janus,
  title = {The {{Janus}}-{{III Translation System}}: {{Speech}}-to-{{Speech Translation}} in {{Multiple Domains}}},
  volume = {15},
  issn = {1573-0573},
  url = {http://dx.doi.org/10.1023/A:1011186420821},
  doi = {10.1023/A:1011186420821},
  abstract = {The Janus-III system translates spoken languages in limiteddomains. The current research focus is on expanding beyond tasksinvolving a single limited semantic domain to significantly broaderand richer domains. To achieve this goal, The MT components of oursystem have been engineered to build and manipulate multi-domain parselattices that are based on modular grammars for multiple semanticdomains. This approach yields solutions to several problems includingmulti-domain disambiguation, segmentation of spoken utterances intosentence units, modularity of system design, and re-use of earliersystems with incompatible output.},
  timestamp = {2017-02-07T15:51:27Z},
  number = {1},
  journaltitle = {Machine Translation},
  author = {Levin, Lori and Lavie, Alon and Woszczyna, Monika and Gates, Donna and Gavaldá, Marsal and Koll, Detlef and Waibel, Alex},
  date = {2000},
  pages = {3--25},
  groups = {other}
}

@article{laskowski2008fundamental,
  title = {The Fundamental Frequency Variation Spectrum},
  timestamp = {2017-02-07T15:51:27Z},
  journaltitle = {Proceedings of FONETIK 2008},
  author = {Laskowski, Kornel and Heldner, Mattias and Edlund, Jens},
  date = {2008},
  pages = {29--32},
  groups = {other}
}

@article{rumelhart_learning_1986,
  title = {Learning Representations by Back-Propagating Errors},
  volume = {323},
  rights = {© 1986 Nature Publishing Group},
  issn = {0028-0836},
  url = {http://www.nature.com/nature/journal/v323/n6088/abs/323533a0.html},
  doi = {10.1038/323533a0},
  timestamp = {2017-02-07T17:18:29Z},
  langid = {english},
  number = {6088},
  journaltitle = {Nature},
  shortjournal = {Nature},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  urldate = {2017-02-07},
  date = {1986-10-09},
  pages = {533--536},
  file = {Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/VA32Q6J5/323533a0.html:text/html},
  groups = {other}
}

@article{kalman_new_1960-1,
  title = {A {{New Approach}} to {{Linear Filtering}} and {{Prediction Problems}}},
  volume = {82},
  timestamp = {2017-02-08T11:29:16Z},
  issue = {Series D},
  journaltitle = {Transactions of the ASME–Journal of Basic Engineering},
  author = {Kalman, Rudolph Emil},
  date = {1960},
  pages = {35--45},
  groups = {other}
}

@article{mikolov_efficient_2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  url = {http://arxiv.org/abs/1301.3781},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  timestamp = {2017-02-08T18:04:19Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1301.3781},
  primaryClass = {cs},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  urldate = {2017-02-08},
  date = {2013-01-16},
  keywords = {Computer Science - Computation and Language},
  file = {arXiv\:1301.3781 PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/IJMBBABM/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf;arXiv.org Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/38E5QHAS/1301.html:text/html},
  groups = {other bc}
}

@article{ward_prosodic_2000,
  title = {Prosodic Features Which Cue Back-Channel Responses in {{English}} and {{Japanese}}},
  volume = {32},
  timestamp = {2017-02-07T15:51:27Z},
  number = {8},
  journaltitle = {Journal of pragmatics},
  author = {Ward, Nigel and Tsukahara, Wataru},
  date = {2000},
  pages = {1177--1207},
  file = {85a7f2a502016c6128668b5b101f1d3954ee.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/6NMXQD9S/85a7f2a502016c6128668b5b101f1d3954ee.pdf:application/pdf},
  groups = {other bc}
}

@article{morency_probabilistic_2010,
  title = {A Probabilistic Multimodal Approach for Predicting Listener Backchannels},
  volume = {20},
  issn = {1573-7454},
  url = {http://dx.doi.org/10.1007/s10458-009-9092-y},
  doi = {10.1007/s10458-009-9092-y},
  abstract = {During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the communication is working and that they should continue speaking. Predicting these backchannel opportunities is an important milestone for building engaging and natural virtual humans. In this paper we show how sequential probabilistic models (e.g., Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to predict listener backchannels using the speaker multimodal output features (e.g., prosody, spoken words and eye gaze). The main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation for probabilistic models. For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically significant improvement over a previously published approach based on hand-crafted rules.},
  timestamp = {2017-02-08T11:29:25Z},
  number = {1},
  journaltitle = {Autonomous Agents and Multi-Agent Systems},
  author = {Morency, Louis-Philippe and de Kok, Iwan and Gratch, Jonathan},
  date = {2010},
  pages = {70--84},
  options = {useprefix=true},
  file = {morency-jaamas08.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/JTVHGSZB/morency-jaamas08.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/2D3AASAZ/10.html:text/html},
  groups = {other bc}
}

@inproceedings{watanabe_voice_1989-1,
  location = {{New York, NY, USA}},
  title = {A {{Voice Reaction System}} with a {{Visualized Response Equivalent}} to {{Nodding}}},
  isbn = {978-0-444-88077-2},
  url = {http://dl.acm.org/citation.cfm?id=92158.92234},
  timestamp = {2017-02-08T11:29:19Z},
  booktitle = {Proceedings of the {{Third International Conference}} on {{Human}}-Computer {{Interaction}}, {{Vol}}.1 on {{Work}} with {{Computers}}: {{Organizational}}, {{Management}}, {{Stress}} and {{Health Aspects}}},
  publisher = {{Elsevier Science Inc.}},
  author = {Watanabe, Tmio and Yuuki, Naohiko},
  urldate = {2017-02-07},
  date = {1989},
  pages = {396--403},
  groups = {other bc}
}

@inproceedings{huang_virtual_2011,
  title = {Virtual {{Rapport}} 2.0},
  rights = {©2011 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-642-23973-1 978-3-642-23974-8},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-23974-8_8},
  abstract = {Rapport, the feeling of being “in sync” with your conversational partners, is argued to underlie many desirable social effects. By generating proper verbal and nonverbal behaviors, virtual humans have been seen to create rapport during interactions with human users. In this paper, we introduce our approach to creating rapport following Tickle-Degnen and Rosenberg’s threefactor (positivity, mutual attention and coordination) theory of rapport. By comparing with a previously published virtual agent, the Rapport Agent, we show that our virtual human predicts the timing of backchannel feedback and end-of-turn more precisely, performs more natural behaviors and, thereby creates much stronger feelings of rapport between users and virtual agents.},
  eventtitle = {International Workshop on Intelligent Virtual Agents},
  timestamp = {2017-02-08T11:29:28Z},
  langid = {english},
  booktitle = {Intelligent {{Virtual Agents}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
  editor = {Vilhjálmsson, Hannes Högni and Kopp, Stefan and Marsella, Stacy and Thórisson, Kristinn R.},
  urldate = {2017-02-07},
  date = {2011-09-15},
  pages = {68--79},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Communication Networks,Coordination,Information Systems Applications (incl. Internet),Multimedia Information Systems,Mutual attention,Positivity,Rapport,Simulation and Modeling,User Interfaces and Human Computer Interaction,Virtual human},
  file = {[PDF] psu.edu:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/4UA83JFQ/Huang et al. - 2011 - Virtual Rapport 2.0.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/2795VX26/978-3-642-23974-8_8.html:text/html;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/BGEIE6I2/978-3-642-23974-8_8.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-642-23974-8_8}
}

@inproceedings{okato_insertion_1996,
  title = {Insertion of Interjectory Response Based on Prosodic Information},
  doi = {10.1109/IVTTA.1996.552766},
  abstract = {This paper investigates `aizuchi' responses (back-channel feedback, interjectory responses or oral nodding) to user's utterances by a computer. In telecommunications, `aizuchi' responses are quite important to inform the hearer's condition to the speaker. In a man-machine telecommunication environment, user's comfortableness may improve if a dialog system can give suitable `aizuchi' to user's utterances. For this purpose, it is important that a system detect conditions of `aizuchi' insertion and insert one at appropriate timing. Firstly, occurances of `aizuchi' were analyzed using a simulated dialog corpus of telephone-shopping-tasks. This showed that there are some prosodic cues in utterances in which `aizuchi' is inserted. Then, timing of `aizuchi' insertion was investigated and perceptual experiments were carried out. Lastly, we made a system which gives `aizuchi' using prosodic information. This system detected suitable positions which agreed with original `aizuchi's with 77\% correct rate},
  eventtitle = {, Third IEEE Workshop on Interactive Voice Technology for Telecommunications Applications, 1996. Proceedings},
  timestamp = {2017-02-08T10:48:12Z},
  booktitle = {, {{Third IEEE Workshop}} on {{Interactive Voice Technology}} for {{Telecommunications Applications}}, 1996. {{Proceedings}}},
  author = {Okato, Y. and Kato, K. and Kamamoto, M. and Itahashi, S.},
  date = {1996-09},
  pages = {85--88},
  keywords = {aizuchi insertion,aizuchi responses,Analytical models,Auditory system,back-channel feedback,dialog system,Feedback,Humans,Information analysis,interactive systems,interjectory response,Man machine systems,man-machine telecommunication environment,natural language interfaces,oral nodding,Permission,prosodic information,Speech analysis,speech processing,speech recognition,Telecommunication computing,telephone-shopping-tasks,Timing,user's utterances},
  file = {00552766.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/2M4C7HNN/00552766.pdf:application/pdf},
  groups = {other bc}
}

@inproceedings{noguchi_prosody-based_1998,
  title = {Prosody-Based Detection of the Context of Backchannel Responses.},
  timestamp = {2017-02-08T10:52:47Z},
  booktitle = {{{ICSLP}}},
  author = {Noguchi, Hiroaki and Den, Yasuharu},
  date = {1998},
  file = {ede41982e4e4f40031967a11f21460abfd67.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/VX9EIUKS/ede41982e4e4f40031967a11f21460abfd67.pdf:application/pdf},
  groups = {other bc}
}

@inproceedings{cathcart_shallow_2003,
  location = {{Stroudsburg, PA, USA}},
  title = {A {{Shallow Model}} of {{Backchannel Continuers}} in {{Spoken Dialogue}}},
  url = {http://dx.doi.org/10.3115/1067807.1067816},
  doi = {10.3115/1067807.1067816},
  abstract = {Spoken dialogue systems would be more acceptable if they were able to produce backchannel continuers such as mm-hmm in naturalistic locations during the user's utterances. Using the HCRC Map Task Corpus as our data source, we describe models for predicting these locations using only limited processing and features of the user's speech that are commonly available, and which therefore could be used as a low-cost improvement for current systems. The baseline model inserts continuers after a predetermined number of words. One further model correlates back-channel continuers with pause duration, while a second predicts their occurrence using trigram POS frequencies. Combining these two models gives the best results.},
  timestamp = {2017-02-08T10:54:26Z},
  booktitle = {Proceedings of the {{Tenth Conference}} on {{European Chapter}} of the {{Association}} for {{Computational Linguistics}} - {{Volume}} 1},
  series = {EACL '03},
  publisher = {{Association for Computational Linguistics}},
  author = {Cathcart, Nicola and Carletta, Jean and Klein, Ewan},
  urldate = {2017-02-08},
  date = {2003},
  pages = {51--58},
  file = {ACM Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/DCKM8TPR/Cathcart et al. - 2003 - A Shallow Model of Backchannel Continuers in Spoke.pdf:application/pdf},
  groups = {other bc}
}

@inproceedings{de_kok_speaker-adaptive_2013,
  location = {{New York, NY, USA}},
  title = {Speaker-Adaptive {{Multimodal Prediction Model}} for {{Listener Responses}}},
  isbn = {978-1-4503-2129-7},
  url = {http://doi.acm.org/10.1145/2522848.2522866},
  doi = {10.1145/2522848.2522866},
  abstract = {The goal of this paper is to analyze and model the variability in speaking styles in dyadic interactions and build a predictive algorithm for listener responses that is able to adapt to these different styles. The end result of this research will be a virtual human able to automatically respond to a human speaker with proper listener responses (e.g., head nods). Our novel speaker-adaptive prediction model is created from a corpus of dyadic interactions where speaker variability is analyzed to identify a subset of prototypical speaker styles. During a live interaction our prediction model automatically identifies the closest prototypical speaker style and predicts listener responses based on this ``communicative style". Central to our approach is the idea of ``speaker profile" which uniquely identifies each speaker and enables the matching between prototypical speakers and new speakers. The paper shows the merits of our speaker-adaptive listener response prediction model by showing improvement over a state-of-the-art approach which does not adapt to the speaker. Besides the merits of speaker-adapta-tion, our experiments highlights the importance of using multimodal features when comparing speakers to select the closest prototypical speaker style.},
  timestamp = {2017-02-08T11:29:29Z},
  booktitle = {Proceedings of the 15th {{ACM}} on {{International Conference}} on {{Multimodal Interaction}}},
  series = {ICMI '13},
  publisher = {{ACM}},
  author = {de Kok, Iwan and Heylen, Dirk and Morency, Louis-Philippe},
  urldate = {2017-02-08},
  date = {2013},
  pages = {51--58},
  keywords = {listener response,machine learning,multimodal,social behavior},
  options = {useprefix=true},
  groups = {other bc}
}

@inproceedings{fujie_conversation_2004,
  title = {A Conversation Robot with Back-Channel Feedback Function Based on Linguistic and Nonlinguistic Information},
  timestamp = {2017-02-08T11:05:05Z},
  booktitle = {Proc. {{ICARA Int}}. {{Conference}} on {{Autonomous Robots}} and {{Agents}}},
  author = {Fujie, Shinya and Fukushima, Kenta and Kobayashi, Tetsunori},
  date = {2004},
  pages = {379--384},
  file = {Paper66_ICARA2004_379_384.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/EPTVCAPU/Paper66_ICARA2004_379_384.pdf:application/pdf},
  groups = {other bc}
}

@inproceedings{takeuchi_timing_2004,
  title = {Timing Detection for Realtime Dialog Systems Using Prosodic and Linguistic Information},
  timestamp = {2017-02-08T11:12:08Z},
  booktitle = {Speech {{Prosody}} 2004, {{International Conference}}},
  author = {Takeuchi, Masashi and Kitaoka, Norihide and Nakagawa, Seiichi},
  date = {2004},
  file = {download.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/76TXE8CI/download.pdf:application/pdf},
  groups = {other bc}
}

@article{kitaoka_response_2005,
  title = {Response {{Timing Detection Using Prosodic}} and {{Linguistic Information}} for {{Human}}-Friendly {{Spoken Dialog Systems}}},
  volume = {20},
  doi = {10.1527/tjsai.20.220},
  abstract = {If a dialog system can respond to the user as reasonably as a human, the interaction will become smoother. Timing of the response such as back-channels and turn-taking plays an important role in such a smooth dialog as in human-human interaction.  We developed a response timing generator for such a dialog system. This generator uses a decision tree to detect the timing based on the features coming from some prosodic and linguistic information. The timing generator decides the action of the system at every 100 ms during the user's pause. In this paper, we describe a robust spoken dialog system using the timing generator. Subjective evaluation proved that almost all of the subjects experienced a friendly feeling from the system.},
  timestamp = {2017-02-08T15:17:18Z},
  number = {3},
  author = {Kitaoka, N. and Takeuchi, M. and R, Nishimura and S, Nakagawa},
  date = {2005},
  pages = {220--228},
  file = {J-Stage - Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/SKQUTZI4/Kitaoka et al. - 2005 - Response Timing Detection Using Prosodic and Lingu.pdf:application/pdf;J-Stage - Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/78N7HKKE/ja.html:text/html},
  groups = {other bc}
}

@inproceedings{nishimura_spoken_2007,
  title = {A {{Spoken Dialog System}} for {{Chat}}-{{Like Conversations Considering Response Timing}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-74628-7_77},
  abstract = {If a dialog system can respond to a user as naturally as a human, the interaction will be smoother. In this research, we aim to develop a dialog system by emulating the human behavior in a chat-like dialog. In this paper, we developed a dialog system which could generate chat-like responses and their timing using a decision tree. The system could perform “collaborative completion,” “aizuchi” (back-channel) and so on. The decision tree utilized the pitch and the power contours of user’s utterance, recognition hypotheses, and response preparation status of the response generator, at every time segment as features to generate response timing.},
  eventtitle = {International Conference on Text, Speech and Dialogue},
  timestamp = {2017-02-08T11:16:20Z},
  langid = {english},
  booktitle = {Text, {{Speech}} and {{Dialogue}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Nishimura, Ryota and Kitaoka, Norihide and Nakagawa, Seiichi},
  urldate = {2017-02-08},
  date = {2007-09-03},
  pages = {599--606},
  file = {Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/W3XP7QU9/Nishimura et al. - 2007 - A Spoken Dialog System for Chat-Like Conversations.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/4FCKIX6W/978-3-540-74628-7_77.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-540-74628-7_77}
}

@inproceedings{morency_predicting_2008,
  title = {Predicting {{Listener Backchannels}}: {{A Probabilistic Multimodal Approach}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-85483-8_18},
  shorttitle = {Predicting {{Listener Backchannels}}},
  abstract = {During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the communication is working and that they should continue speaking. Predicting these backchannel opportunities is an important milestone for building engaging and natural virtual humans. In this paper we show how sequential probabilistic models (e.g., Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to predict listener backchannels using the speaker multimodal output features (e.g., prosody, spoken words and eye gaze). The main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation for probabilistic models. For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically significant improvement over a previously published approach based on hand-crafted rules.},
  eventtitle = {International Workshop on Intelligent Virtual Agents},
  timestamp = {2017-02-08T11:17:21Z},
  langid = {english},
  booktitle = {Intelligent {{Virtual Agents}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Morency, Louis-Philippe and de Kok, Iwan and Gratch, Jonathan},
  urldate = {2017-02-08},
  date = {2008-09-01},
  pages = {176--190},
  file = {Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/4FBKN4DF/Morency et al. - 2008 - Predicting Listener Backchannels A Probabilistic .pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/T4R2S45C/978-3-540-85483-8_18.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-540-85483-8_18}
}

@inproceedings{de_kok_learning_2010,
  location = {{New York, NY, USA}},
  title = {Learning and {{Evaluating Response Prediction Models Using Parallel Listener Consensus}}},
  isbn = {978-1-4503-0414-6},
  url = {http://doi.acm.org/10.1145/1891903.1891908},
  doi = {10.1145/1891903.1891908},
  abstract = {Traditionally listener response prediction models are learned from pre-recorded dyadic interactions. Because of individual differences in behavior, these recordings do not capture the complete ground truth. Where the recorded listener did not respond to an opportunity provided by the speaker, another listener would have responded or vice versa. In this paper, we introduce the concept of parallel listener consensus where the listener responses from multiple parallel interactions are combined to better capture differences and similarities between individuals. We show how parallel listener consensus can be used for both learning and evaluating probabilistic prediction models of listener responses. To improve the learning performance, the parallel consensus helps identifying better negative samples and reduces outliers in the positive samples. We propose a new error measurement called fConsensus which exploits the parallel consensus to better define the concepts of exactness (mislabels) and completeness (missed labels) for prediction models. We present a series of experiments using the MultiLis Corpus where three listeners were tricked into believing that they had a one-on-one conversation with a speaker, while in fact they were recorded in parallel in interaction with the same speaker. In this paper we show that using parallel listener consensus can improve learning performance and represent better evaluation criteria for predictive models.},
  timestamp = {2017-02-08T11:18:24Z},
  booktitle = {International {{Conference}} on {{Multimodal Interfaces}} and the {{Workshop}} on {{Machine Learning}} for {{Multimodal Interaction}}},
  series = {ICMI-MLMI '10},
  publisher = {{ACM}},
  author = {de Kok, Iwan and Ozkan, Derya and Heylen, Dirk and Morency, Louis-Philippe},
  urldate = {2017-02-08},
  date = {2010},
  pages = {3:1--3:8},
  options = {useprefix=true},
  file = {a3-de_kok.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/GV8QP7XB/a3-de_kok.pdf:application/pdf},
  groups = {other bc}
}

@inproceedings{huang_learning_2010,
  title = {Learning {{Backchannel Prediction Model}} from {{Parasocial Consensus Sampling}}: {{A Subjective Evaluation}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-15892-6_17},
  shorttitle = {Learning {{Backchannel Prediction Model}} from {{Parasocial Consensus Sampling}}},
  abstract = {Backchannel feedback is an important kind of nonverbal feedback within face-to-face interaction that signals a person’s interest, attention and willingness to keep listening. Learning to predict when to give such feedback is one of the keys to creating natural and realistic virtual humans. Prediction models are traditionally learned from large corpora of annotated face-to-face interactions, but this approach has several limitations. Previously, we proposed a novel data collection method, Parasocial Consensus Sampling, which addresses these limitations. In this paper, we show that data collected in this manner can produce effective learned models. A subjective evaluation shows that the virtual human driven by the resulting probabilistic model significantly outperforms a previously published rule-based agent in terms of rapport, perceived accuracy and naturalness, and it is even better than the virtual human driven by real listeners’ behavior in some cases.},
  eventtitle = {International Conference on Intelligent Virtual Agents},
  timestamp = {2017-02-08T11:29:24Z},
  langid = {english},
  booktitle = {Intelligent {{Virtual Agents}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
  urldate = {2017-02-08},
  date = {2010-09-20},
  pages = {159--172},
  file = {[PDF] usc.edu:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/4ERVPWPH/Huang et al. - 2010 - Learning backchannel prediction model from parasoc.pdf:application/pdf;Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/SG2SJXRP/Huang et al. - 2010 - Learning Backchannel Prediction Model from Parasoc.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/DCD3H5ZZ/978-3-642-15892-6_17.html:text/html;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/GSFT3FEG/978-3-642-15892-6_17.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-642-15892-6_17}
}

@inproceedings{ozkan_concensus_2010,
  title = {Concensus of {{Self}}-Features for {{Nonverbal Behavior Analysis}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-14715-9_8},
  abstract = {One of the key challenge in social behavior analysis is to automatically discover the subset of features relevant to a specific social signal (e.g., backchannel feedback). The way that these social signals are performed exhibit some variations among different people. In this paper, we present a feature selection approach which first looks at important behaviors for each individual, called self-features, before building a consensus. To enable this approach, we propose a new feature ranking scheme which exploits the sparsity of probabilistic models when trained on human behavior problems. We validated our self-feature concensus approach on the task of listener backchannel prediction and showed improvement over the traditional group-feature approach. Our technique gives researchers a new tool to analyze individual differences in social nonverbal communication.},
  eventtitle = {International Workshop on Human Behavior Understanding},
  timestamp = {2017-02-08T11:23:11Z},
  langid = {english},
  booktitle = {Human {{Behavior Understanding}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Ozkan, Derya and Morency, Louis-Philippe},
  urldate = {2017-02-08},
  date = {2010-08-22},
  pages = {75--86},
  file = {Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/UMQ8Z43A/Ozkan and Morency - 2010 - Concensus of Self-features for Nonverbal Behavior .pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/Q8XZDPZS/978-3-642-14715-9_8.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-642-14715-9_8}
}

@inproceedings{ozkan_latent_2010,
  location = {{Stroudsburg, PA, USA}},
  title = {Latent {{Mixture}} of {{Discriminative Experts}} for {{Multimodal Prediction Modeling}}},
  url = {http://dl.acm.org/citation.cfm?id=1873781.1873878},
  abstract = {During face-to-face conversation, people naturally integrate speech, gestures and higher level language interpretations to predict the right time to start talking or to give backchannel feedback. In this paper we introduce a new model called Latent Mixture of Discriminative Experts which addresses some of the key issues with multimodal language processing: (1) temporal synchrony/asynchrony between modalities, (2) micro dynamics and (3) integration of different levels of interpretation. We present an empirical evaluation on listener nonverbal feedback prediction (e.g., head nod), based on observable behaviors of the speaker. We confirm the importance of combining four types of multimodal features: lexical, syntactic structure, eye gaze, and prosody. We show that our Latent Mixture of Discriminative Experts model outperforms previous approaches based on Conditional Random Fields (CRFs) and Latent-Dynamic CRFs.},
  timestamp = {2017-02-08T11:29:26Z},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Computational Linguistics}}},
  series = {COLING '10},
  publisher = {{Association for Computational Linguistics}},
  author = {Ozkan, Derya and Sagae, Kenji and Morency, Louis-Philippe},
  urldate = {2017-02-08},
  date = {2010},
  pages = {860--868},
  file = {ACM Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/BPCIF7NB/Ozkan et al. - 2010 - Latent Mixture of Discriminative Experts for Multi.pdf:application/pdf;[PDF] semanticscholar.org:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/QSHBFBWG/Ozkan et al. - 2010 - Latent mixture of discriminative experts for multi.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/TM46DM2B/citation.html:text/html},
  groups = {other bc}
}

@inproceedings{poppe_backchannel_2010,
  title = {Backchannel {{Strategies}} for {{Artificial Listeners}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-15892-6_16},
  abstract = {We evaluate multimodal rule-based strategies for backchannel (BC) generation in face-to-face conversations. Such strategies can be used by artificial listeners to determine when to produce a BC in dialogs with human speakers. In this research, we consider features from the speaker’s speech and gaze. We used six rule-based strategies to determine the placement of BCs. The BCs were performed by an intelligent virtual agent using nods and vocalizations. In a user perception experiment, participants were shown video fragments of a human speaker together with an artificial listener who produced BC behavior according to one of the strategies. Participants were asked to rate how likely they thought the BC behavior had been performed by a human listener. We found that the number, timing and type of BC had a significant effect on how human-like the BC behavior was perceived.},
  eventtitle = {International Conference on Intelligent Virtual Agents},
  timestamp = {2017-02-08T11:29:27Z},
  langid = {english},
  booktitle = {Intelligent {{Virtual Agents}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Poppe, Ronald and Truong, Khiet P. and Reidsma, Dennis and Heylen, Dirk},
  urldate = {2017-02-08},
  date = {2010-09-20},
  pages = {146--158},
  file = {Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/9QPS8XFB/Poppe et al. - 2010 - Backchannel Strategies for Artificial Listeners.pdf:application/pdf;[PDF] utwente.nl:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/V3PJQS6T/Poppe et al. - 2010 - Backchannel strategies for artificial listeners.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/QDSF2T42/978-3-642-15892-6_16.html:text/html;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/XF2W7N2U/978-3-642-15892-6_16.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-642-15892-6_16}
}

@article{de_kok_iterative_2014,
  title = {Iterative Perceptual Learning for Social Behavior Synthesis},
  volume = {8},
  issn = {1783-7677, 1783-8738},
  url = {http://link.springer.com/article/10.1007/s12193-013-0132-1},
  doi = {10.1007/s12193-013-0132-1},
  abstract = {We introduce Iterative Perceptual Learning (IPL), a novel approach to learn computational models for social behavior synthesis from corpora of human–human interactions. IPL combines perceptual evaluation with iterative model refinement. Human observers rate the appropriateness of synthesized behaviors in the context of a conversation. These ratings are used to refine the machine learning models that predict the social signal timings. As the ratings correspond to those moments in the conversation where the production of a specific behavior is inappropriate, we regard features extracted at these moments as negative samples for the training of a classifier. This is an advantage over the traditional corpus-based approach to extract negative samples at random non-positive moments. We perform a comparison between IPL and the traditional corpus-based approach on the timing of backchannels for a listener in speaker–listener dialogs. While both models perform similarly in terms of precision and recall scores, there is a tendency that the backchannels generated with IPL are rated as more appropriate. We additionally investigate the effect of the amount of available training data and the variation of training data on the outcome of the models.},
  timestamp = {2017-02-08T11:25:19Z},
  langid = {english},
  number = {3},
  journaltitle = {Journal on Multimodal User Interfaces},
  shortjournal = {J Multimodal User Interfaces},
  author = {de Kok, Iwan and Poppe, Ronald and Heylen, Dirk},
  urldate = {2017-02-08},
  date = {2014-09-01},
  pages = {231--241},
  options = {useprefix=true},
  file = {Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/FBX39ZEN/Kok et al. - 2014 - Iterative perceptual learning for social behavior .pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/S8I7RKNP/s12193-013-0132-1.html:text/html},
  groups = {other bc}
}

@article{ozkan_latent_2013,
  title = {Latent {{Mixture}} of {{Discriminative Experts}}},
  volume = {15},
  issn = {1520-9210},
  doi = {10.1109/TMM.2012.2229263},
  abstract = {In this paper, we introduce a new model called Latent Mixture of Discriminative Experts which can automatically learn the temporal relationship between different modalities. Since, we train separate experts for each modality, LMDE is capable of improving the prediction performance even with limited amount of data. For model interpretation, we present a sparse feature ranking algorithm that exploits L1 regularization. An empirical evaluation is provided on the task of listener backchannel prediction (i.e., head nod). We introduce a new error evaluation metric called User-adaptive Prediction Accuracy that takes into account the difference in people's backchannel responses. Our results confirm the importance of combining five types of multimodal features: lexical, syntactic structure, part-of-speech, visual and prosody. Latent Mixture of Discriminative Experts model outperforms previous approaches.},
  timestamp = {2017-02-08T11:25:53Z},
  number = {2},
  journaltitle = {IEEE Transactions on Multimedia},
  author = {Ozkan, D. and Morency, L. P.},
  date = {2013-02},
  pages = {326--338},
  keywords = {Accuracy,backchannel feedback,Computational modeling,Data models,empirical evaluation,error evaluation metric,evaluation metric,Hidden Markov models,L1 regularization,latent mixture of discriminative experts model,learning (artificial intelligence),lexical feature,listener backchannel prediction,LMDE model,Measurement,mixture of experts,modality learning,model interpretation,multimodal fusion,multimodal integration,multimodal prediction models,part-of-speech feature,prediction performance,Predictive models,prosody feature,sensor fusion,sparse feature ranking algorithm,sparse regularization,syntactic structure feature,Training,user-adaptive prediction accuracy metric,visual feature},
  file = {IEEE Xplore Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/VV363XGQ/Ozkan and Morency - 2013 - Latent Mixture of Discriminative Experts.pdf:application/pdf;IEEE Xplore Abstract Record:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/63MWNTFZ/6359954.html:text/html},
  groups = {other bc}
}

@inproceedings{mueller_using_2015-2,
  title = {Using {{Neural Networks}} for {{Data}}-{{Driven Backchannel Prediction}}: {{A Survey}} on {{Input Features}} and {{Training Techniques}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-20916-6_31},
  shorttitle = {Using {{Neural Networks}} for {{Data}}-{{Driven Backchannel Prediction}}},
  abstract = {In order to make human computer interaction more social, the use of supporting backchannel cues can be beneficial. Such cues can be delivered in different channels like vision, speech or gestures. In this work, we focus on the prediction of acoustic backchannels in terms of speech. Previously, this prediction has been accomplished by using rule-based approaches. But like every rule-based implementation, it is dependent on a fixed set of handwritten rules which have to be changed every time the mechanism is adjusted or different data is used. In this paper we want to overcome these limitations by making use of recent advancements in the field of machine learning. We show that backchannel predictions can be generated by means of a neural network based approach. Such a method has the advantage of depending only on the training data, without the need of handwritten rules.},
  eventtitle = {International Conference on Human-Computer Interaction},
  timestamp = {2017-02-08T11:27:16Z},
  langid = {english},
  booktitle = {Human-{{Computer Interaction}}: {{Interaction Technologies}}},
  publisher = {{Springer, Cham}},
  author = {Mueller, Markus and Leuschner, David and Briem, Lars and Schmidt, Maria and Kilgour, Kevin and Stueker, Sebastian and Waibel, Alex},
  urldate = {2017-02-08},
  date = {2015-08-02},
  pages = {329--340},
  file = {Full Text PDF:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/MRACJQD5/Mueller et al. - 2015 - Using Neural Networks for Data-Driven Backchannel .pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/ZSK7ZIHT/978-3-319-20916-6_31.html:text/html},
  groups = {other bc},
  doi = {10.1007/978-3-319-20916-6_31}
}

@article{truong_rule-based_2010-1,
  title = {A Rule-Based Backchannel Prediction Model Using Pitch and Pause Information},
  url = {http://eprints.eemcs.utwente.nl/18627/},
  timestamp = {2017-02-08T11:28:48Z},
  author = {Truong, Khiet P. and Poppe, R. W. and Heylen, D. K. J.},
  urldate = {2017-02-08},
  date = {2010},
  file = {[PDF] utwente.nl:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/N9ZFJEU2/Truong et al. - 2010 - A rule-based backchannel prediction model using pi.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/ZH87FDCB/18627.html:text/html},
  groups = {other bc}
}

@inproceedings{de_kok_integrating_2012,
  title = {Integrating Backchannel Prediction Models into Embodied Conversational Agents},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-33197-8_28},
  timestamp = {2017-02-08T11:28:48Z},
  booktitle = {International {{Conference}} on {{Intelligent Virtual Agents}}},
  publisher = {{Springer}},
  author = {de Kok, Iwan and Heylen, Dirk},
  urldate = {2017-02-08},
  date = {2012},
  pages = {268--274},
  options = {useprefix=true},
  file = {[PDF] utwente.nl:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/C4RUBRSK/de Kok and Heylen - 2012 - Integrating backchannel prediction models into emb.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/E9PGMASZ/978-3-642-33197-8_28.html:text/html},
  groups = {other bc}
}

@article{de_kok_survey_2012-1,
  title = {A Survey on Evaluation Metrics for Backchannel Prediction Models},
  url = {http://eprints.eemcs.utwente.nl/22780/},
  timestamp = {2017-02-08T11:28:48Z},
  author = {de Kok, I. A. and Heylen, D. K. J.},
  urldate = {2017-02-08},
  date = {2012},
  options = {useprefix=true},
  file = {[PDF] utwente.nl:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/2FVX3NT6/de Kok and Heylen - 2012 - A survey on evaluation metrics for backchannel pre.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/9U38REJ8/22780.html:text/html},
  groups = {other bc}
}

@inproceedings{ozkan_modeling_2011,
  title = {Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts},
  url = {http://dl.acm.org/citation.cfm?id=2002806},
  timestamp = {2017-02-08T11:28:48Z},
  booktitle = {Proceedings of the 49th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}: Short Papers-{{Volume}} 2},
  publisher = {{Association for Computational Linguistics}},
  author = {Ozkan, Derya and Morency, Louis-Philippe},
  urldate = {2017-02-08},
  date = {2011},
  pages = {335--340},
  file = {[PDF] aclweb.org:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/FSJN7SXK/Ozkan and Morency - 2011 - Modeling wisdom of crowds using latent mixture of .pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/ZUFTGG6M/citation.html:text/html},
  groups = {other bc}
}

@inproceedings{de_kok_multimodal_2009,
  title = {Multimodal End-of-Turn Prediction in Multi-Party Meetings},
  url = {http://dl.acm.org/citation.cfm?id=1647332},
  timestamp = {2017-02-08T11:28:48Z},
  booktitle = {Proceedings of the 2009 International Conference on {{Multimodal}} Interfaces},
  publisher = {{ACM}},
  author = {De Kok, Iwan and Heylen, Dirk},
  urldate = {2017-02-08},
  date = {2009},
  pages = {91--98},
  file = {[PDF] utwente.nl:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/FF4V7KG8/De Kok and Heylen - 2009 - Multimodal end-of-turn prediction in multi-party m.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/V75KJMHT/citation.html:text/html},
  groups = {other bc}
}

@inproceedings{ward_using_1996,
  title = {Using Prosodic Clues to Decide When to Produce Back-Channel Utterances},
  volume = {3},
  url = {http://ieeexplore.ieee.org/abstract/document/607961/},
  timestamp = {2017-02-08T14:21:27Z},
  booktitle = {Spoken {{Language}}, 1996. {{ICSLP}} 96. {{Proceedings}}., {{Fourth International Conference}} On},
  publisher = {{IEEE}},
  author = {Ward, Nigel},
  urldate = {2017-02-08},
  date = {1996},
  pages = {1728--1731},
  file = {a062.pdf:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/WJ7SNJMA/a062.pdf:application/pdf;Snapshot:/home/tehdog/.zotero/zotero/h74c1nl7.default/zotero/storage/N3D8WPSQ/607961.html:text/html},
  groups = {other bc}
}

@comment{jabref-meta: databaseType:biblatex;}
@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:other\;0\;;
1 ExplicitGroup:other bc\;0\;;
}

